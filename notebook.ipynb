{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa09430f",
   "metadata": {},
   "source": [
    "## Introduction, Motivation and/or Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b79025",
   "metadata": {},
   "source": [
    "## Data Sources or RL Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396adbdd",
   "metadata": {},
   "source": [
    "## Exploratory Analysis of Data or RL Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77269643",
   "metadata": {},
   "source": [
    "## Models and/or Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd25e1",
   "metadata": {},
   "source": [
    "### Baseline Model Comparison\n",
    "| Model | Accuracy | Macro F1 | ROC AUC(OvR) | Best Class | Worst Class |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| TF-IDF + Logistic Regression | 24.8% | 0.226 | 0.604 | false | pants-fire|\n",
    "| LSTM + Random Embedding | 24% | 0.230 | 0.563 | false | pants-fire |\n",
    "| BERT Network | 25.65% | 0.2389 | 0.6106 | false | true |\n",
    "\n",
    "As is shown above, Bert network has the best performance among the three models. Consequently, we will use Bert network as our final baseline model.\n",
    "\n",
    "**Using BERT as the baseline, we made the following improvements:**\n",
    "\n",
    "| Origin Model | Improvement 1 | Improvement 2 | Improvement 3 | Improvement 4 |\n",
    "| ----------- | ----------- | ----------- | ----------- | ----------- |\n",
    "| Accuracy | 25.65% | 33.15% | 34.41% | 36.07% | 37.33% |\n",
    "| Macro F1 | 0.2389 | 0.2587 | 0.3178 | 0.3315 | 0.3311 |\n",
    "\n",
    "- **Improvement 1: Dual-Branch BERT Architecture:**\n",
    "Designed a two-branch BERT model that processes both the statement and metadata inputs independently through separate BERT encoders. Their outputs are concatenated and enhanced by integrating a credit-based feature vector before classification, allowing the model to incorporate contextual credibility information.\n",
    "\n",
    "- **Improvement 2: Asymmetric Loss Function (ASL):**\n",
    "Employed the Asymmetric Loss function, which effectively handles class imbalance by penalizing false negatives more than false positives‚Äîespecially useful for skewed label distributions in fake news detection.\n",
    "\n",
    "- **Improvement 3: Virtual Adversarial Training (VAT):**\n",
    "Integrated Virtual Adversarial Training to improve model robustness. VAT encourages the model to produce stable predictions under small perturbations, enhancing generalization and defense against adversarial examples.\n",
    "\n",
    "- **Improvement 4: Regularized Dropout (R-Drop):**\n",
    "Applied Regularized Dropout (R-Drop) by enforcing consistency between two stochastic forward passes, which helps reduce overfitting and aligns model predictions during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af4cd9-3c78-4100-b982-4eaf58069c82",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "starting\n",
      "Epoch 1/100\n",
      "----------\n",
      "train total loss: 1.7727\n",
      "train sentiment_acc: 0.2109\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1794    0.1205    0.1442      1676\n",
      "           1     0.2128    0.2732    0.2392      1962\n",
      "           2     0.2103    0.3198    0.2537      2114\n",
      "           3     0.2069    0.1421    0.1685      1654\n",
      "           4     0.2274    0.2546    0.2402      1995\n",
      "           5     0.3000    0.0036    0.0071       839\n",
      "\n",
      "    accuracy                         0.2109     10240\n",
      "   macro avg     0.2228    0.1856    0.1755     10240\n",
      "weighted avg     0.2158    0.2109    0.1964     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[202 443 520 154 357   0]\n",
      " [225 536 651 186 363   1]\n",
      " [224 509 676 239 465   1]\n",
      " [180 391 518 235 328   2]\n",
      " [219 451 600 214 508   3]\n",
      " [ 76 189 250 108 213   3]]\n",
      "val total loss: 1.7263\n",
      "val sentiment_acc: 0.2430\n",
      "\n",
      " Classification Report:\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/root/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000       169\n",
      "           1     0.2829    0.2829    0.2829       251\n",
      "           2     0.2381    0.3427    0.2810       248\n",
      "           3     0.1429    0.0169    0.0302       237\n",
      "           4     0.2346    0.5779    0.3337       263\n",
      "           5     0.0000    0.0000    0.0000       116\n",
      "\n",
      "    accuracy                         0.2430      1284\n",
      "   macro avg     0.1497    0.2034    0.1546      1284\n",
      "weighted avg     0.1757    0.2430    0.1835      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  0  44  42   4  79   0]\n",
      " [  0  71  67   2 111   0]\n",
      " [  0  46  85   7 110   0]\n",
      " [  0  41  77   4 115   0]\n",
      " [  0  41  63   7 152   0]\n",
      " [  0   8  23   4  81   0]]\n",
      "Saving with accuracy of 0.24299065420560748 improved over previous 0\n",
      "Time taken for epoch 1 is 0.5761577844619751 minutes\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train total loss: 1.7124\n",
      "train sentiment_acc: 0.2542\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2414    0.1599    0.1924      1676\n",
      "           1     0.2713    0.3328    0.2989      1962\n",
      "           2     0.2424    0.2786    0.2592      2114\n",
      "           3     0.2458    0.2019    0.2217      1654\n",
      "           4     0.2611    0.3739    0.3075      1995\n",
      "           5     0.1688    0.0155    0.0284       839\n",
      "\n",
      "    accuracy                         0.2542     10240\n",
      "   macro avg     0.2385    0.2271    0.2180     10240\n",
      "weighted avg     0.2459    0.2542    0.2403     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[268 470 368 155 400  15]\n",
      " [238 653 449 217 394  11]\n",
      " [217 494 589 272 527  15]\n",
      " [136 287 411 334 472  14]\n",
      " [176 374 447 243 746   9]\n",
      " [ 75 129 166 138 318  13]]\n",
      "val total loss: 1.6959\n",
      "val sentiment_acc: 0.2578\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4375    0.0414    0.0757       169\n",
      "           1     0.2669    0.5498    0.3594       251\n",
      "           2     0.4286    0.0363    0.0669       248\n",
      "           3     0.2288    0.4557    0.3047       237\n",
      "           4     0.2610    0.2471    0.2539       263\n",
      "           5     0.4444    0.0345    0.0640       116\n",
      "\n",
      "    accuracy                         0.2578      1284\n",
      "   macro avg     0.3445    0.2275    0.1874      1284\n",
      "weighted avg     0.3284    0.2578    0.2072      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[  7  92   3  41  26   0]\n",
      " [  3 138   4  69  37   0]\n",
      " [  1 105   9  95  37   1]\n",
      " [  2  78   2 108  45   2]\n",
      " [  3  84   3 106  65   2]\n",
      " [  0  20   0  53  39   4]]\n",
      "Saving with accuracy of 0.25778816199376947 improved over previous 0.24299065420560748\n",
      "Time taken for epoch 2 is 0.5587228854497274 minutes\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train total loss: 1.6576\n",
      "train sentiment_acc: 0.2959\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3118    0.2220    0.2593      1676\n",
      "           1     0.3100    0.3726    0.3384      1962\n",
      "           2     0.2826    0.3065    0.2941      2114\n",
      "           3     0.2699    0.2424    0.2554      1654\n",
      "           4     0.3007    0.3865    0.3382      1995\n",
      "           5     0.3092    0.1275    0.1806       839\n",
      "\n",
      "    accuracy                         0.2959     10240\n",
      "   macro avg     0.2974    0.2763    0.2777     10240\n",
      "weighted avg     0.2963    0.2959    0.2899     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[372 450 320 146 357  31]\n",
      " [244 731 399 230 317  41]\n",
      " [198 474 648 295 458  41]\n",
      " [136 294 396 401 379  48]\n",
      " [184 316 378 268 771  78]\n",
      " [ 59  93 152 146 282 107]]\n",
      "val total loss: 1.7022\n",
      "val sentiment_acc: 0.2609\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2400    0.2130    0.2257       169\n",
      "           1     0.2917    0.2510    0.2698       251\n",
      "           2     0.2414    0.1976    0.2173       248\n",
      "           3     0.2436    0.3586    0.2901       237\n",
      "           4     0.2695    0.3422    0.3015       263\n",
      "           5     0.3750    0.1034    0.1622       116\n",
      "\n",
      "    accuracy                         0.2609      1284\n",
      "   macro avg     0.2768    0.2443    0.2444      1284\n",
      "weighted avg     0.2693    0.2609    0.2544      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[36 41 35 22 33  2]\n",
      " [40 63 40 50 57  1]\n",
      " [27 37 49 75 57  3]\n",
      " [22 31 38 85 57  4]\n",
      " [23 33 31 76 90 10]\n",
      " [ 2 11 10 41 40 12]]\n",
      "Saving with accuracy of 0.26090342679127726 improved over previous 0.25778816199376947\n",
      "Time taken for epoch 3 is 0.5634446779886881 minutes\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train total loss: 1.5724\n",
      "train sentiment_acc: 0.3510\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3653    0.3228    0.3427      1676\n",
      "           1     0.3423    0.3716    0.3563      1962\n",
      "           2     0.3231    0.3236    0.3233      2114\n",
      "           3     0.3300    0.3210    0.3255      1654\n",
      "           4     0.3738    0.4461    0.4068      1995\n",
      "           5     0.4195    0.2610    0.3218       839\n",
      "\n",
      "    accuracy                         0.3510     10240\n",
      "   macro avg     0.3590    0.3410    0.3461     10240\n",
      "weighted avg     0.3526    0.3510    0.3493     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[541 370 278 132 311  44]\n",
      " [286 729 426 240 239  42]\n",
      " [217 424 684 306 420  63]\n",
      " [119 307 337 531 295  65]\n",
      " [245 220 304 247 890  89]\n",
      " [ 73  80  88 153 226 219]]\n",
      "val total loss: 1.7966\n",
      "val sentiment_acc: 0.2593\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2500    0.3787    0.3012       169\n",
      "           1     0.2443    0.4303    0.3117       251\n",
      "           2     0.2963    0.1613    0.2089       248\n",
      "           3     0.2433    0.3460    0.2857       237\n",
      "           4     0.3167    0.0722    0.1176       263\n",
      "           5     0.3704    0.1724    0.2353       116\n",
      "\n",
      "    accuracy                         0.2593      1284\n",
      "   macro avg     0.2868    0.2602    0.2434      1284\n",
      "weighted avg     0.2811    0.2593    0.2390      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 64  71  10  20   2   2]\n",
      " [ 63 108  24  44   8   4]\n",
      " [ 43  84  40  66  11   4]\n",
      " [ 38  68  31  82  10   8]\n",
      " [ 35  82  24  87  19  16]\n",
      " [ 13  29   6  38  10  20]]\n",
      "Time taken for epoch 4 is 0.5509525934855143 minutes\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train total loss: 1.4368\n",
      "train sentiment_acc: 0.4199\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4204    0.4033    0.4117      1676\n",
      "           1     0.4309    0.4511    0.4407      1962\n",
      "           2     0.3838    0.3827    0.3832      2114\n",
      "           3     0.4097    0.3742    0.3912      1654\n",
      "           4     0.4307    0.4887    0.4579      1995\n",
      "           5     0.4835    0.4005    0.4381       839\n",
      "\n",
      "    accuracy                         0.4199     10240\n",
      "   macro avg     0.4265    0.4168    0.4205     10240\n",
      "weighted avg     0.4203    0.4199    0.4192     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[676 328 263  91 274  44]\n",
      " [267 885 345 239 194  32]\n",
      " [254 339 809 269 378  65]\n",
      " [123 255 318 619 249  90]\n",
      " [233 183 300 176 975 128]\n",
      " [ 55  64  73 117 194 336]]\n",
      "val total loss: 1.8014\n",
      "val sentiment_acc: 0.2648\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2192    0.3373    0.2657       169\n",
      "           1     0.2442    0.2948    0.2671       251\n",
      "           2     0.3481    0.1895    0.2454       248\n",
      "           3     0.2723    0.2700    0.2712       237\n",
      "           4     0.2821    0.2091    0.2402       263\n",
      "           5     0.2756    0.3707    0.3162       116\n",
      "\n",
      "    accuracy                         0.2648      1284\n",
      "   macro avg     0.2736    0.2786    0.2676      1284\n",
      "weighted avg     0.2768    0.2648    0.2624      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[57 48 19 17 18 10]\n",
      " [72 74 24 37 29 15]\n",
      " [47 58 47 39 36 21]\n",
      " [40 52 23 64 38 20]\n",
      " [33 53 18 57 55 47]\n",
      " [11 18  4 21 19 43]]\n",
      "Saving with accuracy of 0.26479750778816197 improved over previous 0.26090342679127726\n",
      "Time taken for epoch 5 is 0.563946537176768 minutes\n",
      "\n",
      "Epoch 6/100\n",
      "----------\n",
      "train total loss: 1.2078\n",
      "train sentiment_acc: 0.5335\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5274    0.5227    0.5250      1676\n",
      "           1     0.5178    0.5352    0.5263      1962\n",
      "           2     0.4955    0.4716    0.4833      2114\n",
      "           3     0.5144    0.5060    0.5102      1654\n",
      "           4     0.5756    0.6201    0.5970      1995\n",
      "           5     0.6107    0.5554    0.5818       839\n",
      "\n",
      "    accuracy                         0.5335     10240\n",
      "   macro avg     0.5402    0.5352    0.5373     10240\n",
      "weighted avg     0.5331    0.5335    0.5329     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 876  250  204   91  211   44]\n",
      " [ 251 1050  279  204  145   33]\n",
      " [ 205  307  997  257  303   45]\n",
      " [  97  245  269  837  139   67]\n",
      " [ 175  124  226  125 1237  108]\n",
      " [  57   52   37  113  114  466]]\n",
      "val total loss: 2.0419\n",
      "val sentiment_acc: 0.2726\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2210    0.4615    0.2989       169\n",
      "           1     0.2959    0.1992    0.2381       251\n",
      "           2     0.2637    0.2903    0.2764       248\n",
      "           3     0.2344    0.2068    0.2197       237\n",
      "           4     0.3419    0.3042    0.3219       263\n",
      "           5     0.4565    0.1810    0.2593       116\n",
      "\n",
      "    accuracy                         0.2726      1284\n",
      "   macro avg     0.3022    0.2738    0.2690      1284\n",
      "weighted avg     0.2924    0.2726    0.2692      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[78 27 28 20 15  1]\n",
      " [84 50 52 29 31  5]\n",
      " [61 35 72 39 37  4]\n",
      " [59 24 57 49 42  6]\n",
      " [52 25 44 53 80  9]\n",
      " [19  8 20 19 29 21]]\n",
      "Saving with accuracy of 0.27258566978193144 improved over previous 0.26479750778816197\n",
      "Time taken for epoch 6 is 0.5648258368174235 minutes\n",
      "\n",
      "Epoch 7/100\n",
      "----------\n",
      "train total loss: 0.9476\n",
      "train sentiment_acc: 0.6486\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6515    0.6569    0.6542      1676\n",
      "           1     0.6351    0.6504    0.6427      1962\n",
      "           2     0.5913    0.5728    0.5819      2114\n",
      "           3     0.6291    0.6336    0.6313      1654\n",
      "           4     0.6937    0.7153    0.7043      1995\n",
      "           5     0.7519    0.6901    0.7197       839\n",
      "\n",
      "    accuracy                         0.6486     10240\n",
      "   macro avg     0.6588    0.6532    0.6557     10240\n",
      "weighted avg     0.6488    0.6486    0.6485     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[1101  188  168   58  135   26]\n",
      " [ 180 1276  230  175   77   24]\n",
      " [ 175  239 1211  213  249   27]\n",
      " [  68  188  216 1048   94   40]\n",
      " [ 130   78  197   89 1427   74]\n",
      " [  36   40   26   83   75  579]]\n",
      "val total loss: 2.2818\n",
      "val sentiment_acc: 0.2593\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2181    0.3136    0.2573       169\n",
      "           1     0.2791    0.1912    0.2270       251\n",
      "           2     0.2907    0.2016    0.2381       248\n",
      "           3     0.2584    0.2911    0.2738       237\n",
      "           4     0.2658    0.3042    0.2837       263\n",
      "           5     0.2558    0.2845    0.2694       116\n",
      "\n",
      "    accuracy                         0.2593      1284\n",
      "   macro avg     0.2613    0.2644    0.2582      1284\n",
      "weighted avg     0.2647    0.2593    0.2572      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[53 35 20 17 33 11]\n",
      " [62 48 41 42 45 13]\n",
      " [47 26 50 54 51 20]\n",
      " [38 25 29 69 58 18]\n",
      " [34 30 25 60 80 34]\n",
      " [ 9  8  7 25 34 33]]\n",
      "Time taken for epoch 7 is 0.5511609514554342 minutes\n",
      "\n",
      "Epoch 8/100\n",
      "----------\n",
      "train total loss: 0.6804\n",
      "train sentiment_acc: 0.7562\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7550    0.7613    0.7582      1676\n",
      "           1     0.7383    0.7462    0.7422      1962\n",
      "           2     0.7218    0.6873    0.7041      2114\n",
      "           3     0.7491    0.7545    0.7518      1654\n",
      "           4     0.7858    0.8221    0.8035      1995\n",
      "           5     0.8265    0.7890    0.8073       839\n",
      "\n",
      "    accuracy                         0.7562     10240\n",
      "   macro avg     0.7627    0.7601    0.7612     10240\n",
      "weighted avg     0.7559    0.7562    0.7558     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[1276  141  121   24  101   13]\n",
      " [ 129 1464  154  137   57   21]\n",
      " [ 145  157 1453  158  179   22]\n",
      " [  38  139  148 1248   47   34]\n",
      " [  81   56  126   43 1640   49]\n",
      " [  21   26   11   56   63  662]]\n",
      "val total loss: 2.5662\n",
      "val sentiment_acc: 0.2679\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2415    0.3787    0.2949       169\n",
      "           1     0.2984    0.2271    0.2579       251\n",
      "           2     0.2342    0.2984    0.2624       248\n",
      "           3     0.2602    0.2700    0.2650       237\n",
      "           4     0.3294    0.2129    0.2587       263\n",
      "           5     0.3021    0.2500    0.2736       116\n",
      "\n",
      "    accuracy                         0.2679      1284\n",
      "   macro avg     0.2776    0.2729    0.2688      1284\n",
      "weighted avg     0.2781    0.2679    0.2665      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[64 35 36 20 11  3]\n",
      " [59 57 65 36 22 12]\n",
      " [50 35 74 44 32 13]\n",
      " [38 32 61 64 32 10]\n",
      " [40 26 56 56 56 29]\n",
      " [14  6 24 26 17 29]]\n",
      "Time taken for epoch 8 is 0.5508858799934387 minutes\n",
      "\n",
      "Epoch 9/100\n",
      "----------\n",
      "train total loss: 0.4342\n",
      "train sentiment_acc: 0.8483\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8509    0.8616    0.8562      1676\n",
      "           1     0.8348    0.8369    0.8358      1962\n",
      "           2     0.8170    0.8070    0.8120      2114\n",
      "           3     0.8398    0.8368    0.8383      1654\n",
      "           4     0.8760    0.8782    0.8771      1995\n",
      "           5     0.9036    0.9046    0.9041       839\n",
      "\n",
      "    accuracy                         0.8483     10240\n",
      "   macro avg     0.8537    0.8542    0.8539     10240\n",
      "weighted avg     0.8482    0.8483    0.8483     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[1444   77   72   14   56   13]\n",
      " [  84 1642  110   93   26    7]\n",
      " [  80  109 1706   97  116    6]\n",
      " [  22   94  109 1384   24   21]\n",
      " [  57   36   84   32 1752   34]\n",
      " [  10    9    7   28   26  759]]\n",
      "val total loss: 3.0699\n",
      "val sentiment_acc: 0.2702\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2017    0.4201    0.2726       169\n",
      "           1     0.3421    0.2072    0.2581       251\n",
      "           2     0.2561    0.2944    0.2739       248\n",
      "           3     0.2910    0.2321    0.2582       237\n",
      "           4     0.3182    0.2662    0.2899       263\n",
      "           5     0.3023    0.2241    0.2574       116\n",
      "\n",
      "    accuracy                         0.2702      1284\n",
      "   macro avg     0.2852    0.2740    0.2683      1284\n",
      "weighted avg     0.2891    0.2702    0.2695      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[71 26 30 18 19  5]\n",
      " [83 52 55 24 26 11]\n",
      " [61 28 73 30 42 14]\n",
      " [56 20 54 55 40 12]\n",
      " [58 21 52 44 70 18]\n",
      " [23  5 21 18 23 26]]\n",
      "Time taken for epoch 9 is 0.5511734445889791 minutes\n",
      "‚õî Early stopping at epoch 9\n",
      "Training complete in 5m 2s\n",
      "Best val Acc: 0.272586\n",
      "/root/autodl-tmp/Fake-News-Detection-with-two-Branch-BRET-Network-main/bert_origin.py:630: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('bert_model_ori.pth'))\n",
      "\n",
      "üß™ Evaluation Results:\n",
      "üìâ Average Loss: 2.0107\n",
      "‚úÖ Accuracy: 25.65%\n",
      "\n",
      "üìä Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2290    0.3798    0.2857       208\n",
      "           1     0.2475    0.2033    0.2232       241\n",
      "           2     0.2415    0.2679    0.2540       265\n",
      "           3     0.2683    0.2075    0.2340       212\n",
      "           4     0.3136    0.2972    0.3052       249\n",
      "           5     0.2667    0.0870    0.1311        92\n",
      "\n",
      "    accuracy                         0.2565      1267\n",
      "   macro avg     0.2611    0.2405    0.2389      1267\n",
      "weighted avg     0.2611    0.2565    0.2512      1267\n",
      "\n",
      "üîç Confusion Matrix:\n",
      "[[79 47 44 14 22  2]\n",
      " [78 49 55 29 28  2]\n",
      " [58 44 71 38 50  4]\n",
      " [47 25 52 44 38  6]\n",
      " [64 22 56 25 74  8]\n",
      " [19 11 16 14 24  8]]\n",
      "üìä ROC AUC (OvR Macro): 0.6106\n",
      "Figure(600x500)\n"
     ]
    }
   ],
   "source": [
    "!python bert_origin.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5cd9c",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61636ed2-2b8b-49a0-b010-79fc0415abed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7f58241d9130>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f582412fd70>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f5823923c80>}\n",
      "{'train': 10240, 'val': 1284, 'test': 1267}\n",
      "starting\n",
      "Epoch 1/100\n",
      "----------\n",
      "train total loss: 1.2699\n",
      "train sentiment_acc: 0.2754\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2338    0.1014    0.1415      1676\n",
      "           1     0.3389    0.3818    0.3591      1962\n",
      "           2     0.2555    0.3543    0.2969      2114\n",
      "           3     0.2060    0.1282    0.1580      1654\n",
      "           4     0.2664    0.4100    0.3230      1995\n",
      "           5     0.4469    0.1454    0.2194       839\n",
      "\n",
      "    accuracy                         0.2754     10240\n",
      "   macro avg     0.2913    0.2535    0.2497     10240\n",
      "weighted avg     0.2778    0.2754    0.2597     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[170 443 557 123 370  13]\n",
      " [185 749 581  96 343   8]\n",
      " [180 492 749 161 522  10]\n",
      " [ 88 242 434 212 659  19]\n",
      " [ 85 228 470 293 818 101]\n",
      " [ 19  56 140 144 358 122]]\n",
      "val total loss: 1.1401\n",
      "val sentiment_acc: 0.3505\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2150    0.2722    0.2402       169\n",
      "           1     0.3914    0.6534    0.4896       251\n",
      "           2     0.0000    0.0000    0.0000       248\n",
      "           3     0.2802    0.4304    0.3394       237\n",
      "           4     0.4416    0.3878    0.4130       263\n",
      "           5     0.6792    0.3103    0.4260       116\n",
      "\n",
      "    accuracy                         0.3505      1284\n",
      "   macro avg     0.3346    0.3424    0.3180      1284\n",
      "weighted avg     0.3083    0.3505    0.3130      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 46  69   0  34  20   0]\n",
      " [ 38 164   1  34  14   0]\n",
      " [ 51 103   0  76  17   1]\n",
      " [ 40  45   1 102  46   3]\n",
      " [ 31  31   1  85 102  13]\n",
      " [  8   7   0  33  32  36]]\n",
      "Saving with accuracy of 0.35046728971962615 improved over previous 0\n",
      "Time taken for epoch1 is 2.1106353123982746 minutes\n",
      "\n",
      "Epoch 2/100\n",
      "----------\n",
      "train total loss: 1.1445\n",
      "train sentiment_acc: 0.3438\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2898    0.1760    0.2190      1676\n",
      "           1     0.4133    0.4832    0.4455      1962\n",
      "           2     0.3005    0.3548    0.3254      2114\n",
      "           3     0.2808    0.2013    0.2345      1654\n",
      "           4     0.3513    0.5133    0.4171      1995\n",
      "           5     0.5136    0.2026    0.2906       839\n",
      "\n",
      "    accuracy                         0.3438     10240\n",
      "   macro avg     0.3582    0.3219    0.3220     10240\n",
      "weighted avg     0.3445    0.3438    0.3313     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 295  512  446  130  280   13]\n",
      " [ 220  948  458  130  194   12]\n",
      " [ 213  535  750  238  365   13]\n",
      " [ 124  144  383  333  638   32]\n",
      " [ 138  124  375  243 1024   91]\n",
      " [  28   31   84  112  414  170]]\n",
      "val total loss: 1.0928\n",
      "val sentiment_acc: 0.3676\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2632    0.2663    0.2647       169\n",
      "           1     0.6642    0.3625    0.4691       251\n",
      "           2     0.2890    0.6048    0.3911       248\n",
      "           3     0.2432    0.0380    0.0657       237\n",
      "           4     0.3889    0.5589    0.4587       263\n",
      "           5     0.7143    0.2586    0.3797       116\n",
      "\n",
      "    accuracy                         0.3676      1284\n",
      "   macro avg     0.4271    0.3482    0.3382      1284\n",
      "weighted avg     0.4094    0.3676    0.3425      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 45  17  72   1  34   0]\n",
      " [ 39  91  94   6  21   0]\n",
      " [ 37  19 150  10  31   1]\n",
      " [ 26   6 104   9  91   1]\n",
      " [ 21   3  73   9 147  10]\n",
      " [  3   1  26   2  54  30]]\n",
      "Saving with accuracy of 0.367601246105919 improved over previous 0.35046728971962615\n",
      "Time taken for epoch2 is 2.104286261399587 minutes\n",
      "\n",
      "Epoch 3/100\n",
      "----------\n",
      "train total loss: 1.0917\n",
      "train sentiment_acc: 0.3900\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3625    0.2894    0.3218      1676\n",
      "           1     0.4514    0.4898    0.4698      1962\n",
      "           2     0.3600    0.4158    0.3859      2114\n",
      "           3     0.3322    0.2418    0.2799      1654\n",
      "           4     0.3837    0.5268    0.4440      1995\n",
      "           5     0.5619    0.2598    0.3553       839\n",
      "\n",
      "    accuracy                         0.3900     10240\n",
      "   macro avg     0.4086    0.3706    0.3761     10240\n",
      "weighted avg     0.3946    0.3900    0.3832     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 485  433  384  102  260   12]\n",
      " [ 269  961  434  135  153   10]\n",
      " [ 281  410  879  208  316   20]\n",
      " [ 122  174  337  400  581   40]\n",
      " [ 157  132  323  244 1051   88]\n",
      " [  24   19   85  115  378  218]]\n",
      "val total loss: 1.0969\n",
      "val sentiment_acc: 0.3598\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2540    0.2840    0.2682       169\n",
      "           1     0.5443    0.3426    0.4205       251\n",
      "           2     0.2922    0.5444    0.3803       248\n",
      "           3     0.2958    0.2658    0.2800       237\n",
      "           4     0.4591    0.3840    0.4182       263\n",
      "           5     0.6905    0.2500    0.3671       116\n",
      "\n",
      "    accuracy                         0.3598      1284\n",
      "   macro avg     0.4226    0.3451    0.3557      1284\n",
      "weighted avg     0.4073    0.3598    0.3615      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 48  24  62  18  16   1]\n",
      " [ 44  86  87  23  11   0]\n",
      " [ 40  30 135  29  13   1]\n",
      " [ 31  11  89  63  42   1]\n",
      " [ 21   6  69  56 101  10]\n",
      " [  5   1  20  24  37  29]]\n",
      "Time taken for epoch3 is 3.0647680004437765 minutes\n",
      "\n",
      "Epoch 4/100\n",
      "----------\n",
      "train total loss: 1.0054\n",
      "train sentiment_acc: 0.4476\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4573    0.3896    0.4207      1676\n",
      "           1     0.5068    0.5311    0.5187      1962\n",
      "           2     0.4316    0.4924    0.4600      2114\n",
      "           3     0.3794    0.3023    0.3365      1654\n",
      "           4     0.4191    0.5338    0.4696      1995\n",
      "           5     0.5814    0.3361    0.4260       839\n",
      "\n",
      "    accuracy                         0.4476     10240\n",
      "   macro avg     0.4626    0.4309    0.4386     10240\n",
      "weighted avg     0.4516    0.4476    0.4439     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 653  388  311   90  225    9]\n",
      " [ 271 1042  376  149  117    7]\n",
      " [ 240  338 1041  203  272   20]\n",
      " [ 102  164  313  500  521   54]\n",
      " [ 139  106  299  273 1065  113]\n",
      " [  23   18   72  103  341  282]]\n",
      "val total loss: 1.1159\n",
      "val sentiment_acc: 0.3559\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2607    0.3254    0.2895       169\n",
      "           1     0.4037    0.5179    0.4538       251\n",
      "           2     0.2887    0.3387    0.3117       248\n",
      "           3     0.2967    0.3080    0.3023       237\n",
      "           4     0.4910    0.3118    0.3814       263\n",
      "           5     0.7021    0.2845    0.4049       116\n",
      "\n",
      "    accuracy                         0.3559      1284\n",
      "   macro avg     0.4072    0.3477    0.3572      1284\n",
      "weighted avg     0.3878    0.3559    0.3575      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 55  50  34  17  12   1]\n",
      " [ 39 130  55  21   6   0]\n",
      " [ 47  71  84  34  11   1]\n",
      " [ 39  41  55  73  28   1]\n",
      " [ 25  24  49  72  82  11]\n",
      " [  6   6  14  29  28  33]]\n",
      "Time taken for epoch4 is 3.0663009802500407 minutes\n",
      "\n",
      "Epoch 5/100\n",
      "----------\n",
      "train total loss: 0.8717\n",
      "train sentiment_acc: 0.5475\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5700    0.5221    0.5450      1676\n",
      "           1     0.5802    0.6086    0.5940      1962\n",
      "           2     0.5526    0.5918    0.5715      2114\n",
      "           3     0.5016    0.4813    0.4912      1654\n",
      "           4     0.5120    0.5759    0.5421      1995\n",
      "           5     0.6178    0.4064    0.4903       839\n",
      "\n",
      "    accuracy                         0.5475     10240\n",
      "   macro avg     0.5557    0.5310    0.5390     10240\n",
      "weighted avg     0.5499    0.5475    0.5461     10240\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 875  324  216   76  178    7]\n",
      " [ 231 1194  282  149   99    7]\n",
      " [ 193  284 1251  164  195   27]\n",
      " [  70  158  215  796  354   61]\n",
      " [ 149   88  239  261 1149  109]\n",
      " [  17   10   61  141  269  341]]\n",
      "val total loss: 1.2439\n",
      "val sentiment_acc: 0.3310\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2378    0.4615    0.3139       169\n",
      "           1     0.3927    0.4741    0.4296       251\n",
      "           2     0.2624    0.2984    0.2792       248\n",
      "           3     0.2833    0.2152    0.2446       237\n",
      "           4     0.4768    0.2738    0.3478       263\n",
      "           5     0.7750    0.2672    0.3974       116\n",
      "\n",
      "    accuracy                         0.3310      1284\n",
      "   macro avg     0.4047    0.3317    0.3354      1284\n",
      "weighted avg     0.3787    0.3310    0.3315      1284\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 78  44  25  13   8   1]\n",
      " [ 70 119  46  11   5   0]\n",
      " [ 65  74  74  23  11   1]\n",
      " [ 59  35  64  51  27   1]\n",
      " [ 45  24  61  55  72   6]\n",
      " [ 11   7  12  27  28  31]]\n",
      "Time taken for epoch5 is 3.0673174301783246 minutes\n",
      "‚õî Early stopping at epoch 5\n",
      "Training complete in 13m 25s\n",
      "Best val Acc: 0.367601\n",
      "train_acc:  [array(0.27539062), array(0.34375), array(0.39003906), array(0.44755859), array(0.54746094)]\n",
      "val_acc:  [array(0.35981308), array(0.355919), array(0.33099688)]\n",
      "train_loss:  [1.2698943495750428, 1.1445466786623002, 1.091663559526205, 1.0054352380335332, 0.8717063792049885]\n",
      "val_loss:  [1.0968712675979948, 1.1158711939957282, 1.243940054813278]\n",
      "/root/autodl-tmp/Fake-News-Detection-with-two-Branch-BRET-Network-main/bert_network_with_VAT_RDrop.py:682: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('bert_model.pth'))\n",
      "\n",
      " Evaluation Results:\n",
      " Average Loss: 1.2895\n",
      " Accuracy: 37.33%\n",
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3442    0.2548    0.2928       208\n",
      "           1     0.5448    0.3278    0.4093       241\n",
      "           2     0.3144    0.6264    0.4187       265\n",
      "           3     0.3784    0.0660    0.1124       212\n",
      "           4     0.3844    0.5743    0.4605       249\n",
      "           5     0.5806    0.1957    0.2927        92\n",
      "\n",
      "    accuracy                         0.3733      1267\n",
      "   macro avg     0.4245    0.3408    0.3311      1267\n",
      "weighted avg     0.4069    0.3733    0.3441      1267\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "[[ 53  30  91   2  29   3]\n",
      " [ 36  79 105   4  17   0]\n",
      " [ 29  21 166   7  42   0]\n",
      " [ 15  10  85  14  85   3]\n",
      " [ 19   5  68   7 143   7]\n",
      " [  2   0  13   3  56  18]]\n",
      "Figure(600x500)\n"
     ]
    }
   ],
   "source": [
    "!python bert_network_with_VAT_RDrop.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535e7a23",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e03116",
   "metadata": {},
   "source": [
    "## Writing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
